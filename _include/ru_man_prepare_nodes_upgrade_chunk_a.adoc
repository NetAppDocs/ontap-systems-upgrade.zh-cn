= 


在更换原始节点之前，您必须确认它们位于 HA 对中，没有缺失或故障磁盘，可以访问彼此的存储，并且不拥有分配给集群中其他节点的数据 LIF 。此外，您还必须收集有关原始节点的信息，如果集群位于 SAN 环境中，请确认集群中的所有节点都处于仲裁状态。

.步骤
. 确认每个原始节点都有足够的资源，可以在接管模式下为这两个节点的工作负载提供充分的支持。
+
请参见 link:other_references.html["参考资料"] 链接到 _High Availability management_ 并按照 _Best Practices for HA pairs_一 节进行操作。原始节点均不应以 50% 以上的利用率运行；如果某个节点以低于 50% 的利用率运行，则它可以在控制器升级期间处理这两个节点的负载。

. 完成以下子步骤，为原始节点创建性能基线：
+
.. 确保诊断用户帐户已解锁。
+
* 重要信息 * ：诊断用户帐户仅用于低级别诊断，只能在技术支持的指导下使用。

+
* 重要信息 * ：有关解锁用户帐户的信息，请参见 link:other_references.html["参考资料"] 链接到系统管理参考。

.. 请参见 link:other_references.html["参考资料"] 链接到 _NetApp 支持站点 _ 并下载性能和统计信息收集器（ Perfstat Converged ）。
+
使用 perfstat Converged 工具，您可以建立性能基线，以便在升级后进行比较。

.. 按照 NetApp 支持站点上的说明创建性能基线。


. 请参见 link:other_references.html["参考资料"] 链接到 _NetApp 支持站点 _ 并在 NetApp 支持站点上创建支持案例。
+
您可以使用案例报告升级期间可能出现的任何问题。

. 验证 node3 和 node4 的 NVMEM 或 NVRAM 电池是否已充电，如果未充电，请为其充电。
+
您必须物理检查 node3 和 node4 以查看 NVMEM 或 NVRAM 电池是否已充电。有关 node3 和 node4 型号的 LED 的信息，请参见 link:other_references.html["参考资料"] 链接到 _SIL_ Hardware Universe 。

+

WARNING: * 注意 * 请勿尝试清除 NVRAM 内容。如果需要清除 NVRAM 的内容，请联系 NetApp 技术支持。

. 检查 node3 和 node4 上的 ONTAP 版本。
+
新节点上安装的 ONTAP 9.x 版本必须与原始节点上安装的版本相同。如果新节点安装的 ONTAP 版本不同，则必须在安装新控制器后通过网络启动这些控制器。有关如何升级 ONTAP 的说明，请参见 link:other_references.html["参考资料"] 链接到 _Upgrade ONTAP 。

+
有关 node3 和 node4 上的 ONTAP 版本的信息应包含在装运箱中。节点启动时会显示 ONTAP 版本，您也可以将节点启动至维护模式并运行命令：

+
`ve版本`

. 检查 node1 和 node2 上是否有两个或四个集群 LIF ：
+
`network interface show -role cluster`

+
系统将显示任何集群 LIF ，如以下示例所示：

+
....
cluster::> network interface show -role cluster
        Logical    Status     Network          Current  Current Is
Vserver Interface  Admin/Oper Address/Mask     Node     Port    Home
------- ---------- ---------- ---------------- -------- ------- ----
node1
        clus1      up/up      172.17.177.2/24  node1    e0c     true
        clus2      up/up      172.17.177.6/24  node1    e0e     true
node2
        clus1      up/up      172.17.177.3/24  node2    e0c     true
        clus2      up/up      172.17.177.7/24  node2    e0e     true
....
. 如果 node1 或 node2 上有两个或四个集群 LIF ，请通过完成以下子步骤确保您可以在所有可用路径上对两个集群 LIF 执行 ping 操作：
+
.. 输入高级权限级别：
+
`set -privilege advanced`

+
系统将显示以下消息：

+
....
Warning: These advanced commands are potentially dangerous; use them only when directed to do so by NetApp personnel.
Do you wish to continue? (y or n):
....
.. 输入 `y` 。
.. 对节点执行 Ping 操作并测试连接：
+
`cluster ping-cluster -node node_name`

+
系统将显示类似于以下示例的消息：

+
....
cluster::*> cluster ping-cluster -node node1
Host is node1
Getting addresses from network interface table...
Local = 10.254.231.102 10.254.91.42
Remote = 10.254.42.25 10.254.16.228
Ping status:
...
Basic connectivity succeeds on 4 path(s) Basic connectivity fails on 0 path(s)
................
Detected 1500 byte MTU on 4 path(s):
Local 10.254.231.102 to Remote 10.254.16.228
Local 10.254.231.102 to Remote 10.254.42.25
Local 10.254.91.42 to Remote 10.254.16.228
Local 10.254.91.42 to Remote 10.254.42.25
Larger than PMTU communication succeeds on 4 path(s)
RPC status:
2 paths up, 0 paths down (tcp check)
2 paths up, 0 paths down (udp check)
....
+
如果节点使用两个集群端口，您应看到它能够在四个路径上进行通信，如示例所示。

.. 返回到管理级别权限：
+
`set -privilege admin`



. 确认 node1 和 node2 位于 HA 对中，并验证节点是否彼此连接，以及是否可以进行接管：
+
`s存储故障转移显示`

+
以下示例显示了节点彼此连接并可进行接管时的输出：

+
....
cluster::> storage failover show
                              Takeover
Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------
node1          node2          true     Connected to node2
node2          node1          true     Connected to node1
....
+
两个节点均不应处于部分交还状态。以下示例显示 node1 处于部分交还状态：

+
....
cluster::> storage failover show
                              Takeover
Node           Partner        Possible State Description
-------------- -------------- -------- -------------------------------
node1          node2          true     Connected to node2, Partial giveback
node2          node1          true     Connected to node1
....
+
如果任一节点处于部分交还状态，请使用 `storage failover giveback` 命令执行交还，然后使用 `storage failover show-giveback` 命令确保仍不需要交还聚合。有关命令的详细信息，请参见 link:other_references.html["参考资料"] 链接到 _High Availability management_ 。

. 【 man_prepare_nodes_step9]] 确认 node1 和 node2 均不拥有其当前所有者（而不是主所有者）的聚合：
+
`storage aggregate show -node <node_name> -is-home false -fields owner-name ， homename ， state`

+
如果 node1 和 node2 都不拥有当前所有者（而不是主所有者）的聚合，则系统将返回类似于以下示例的消息：

+
....
cluster::> storage aggregate show -node node2 -is-home false -fields owner-name,homename,state
There are no entries matching your query.
....
+
以下示例显示了一个名为 node2 的节点的命令输出，该节点是四个聚合的主所有者，但不是当前所有者：

+
....
cluster::> storage aggregate show -node node2 -is-home false
               -fields owner-name,home-name,state

aggregate     home-name    owner-name   state
------------- ------------ ------------ ------
aggr1         node1        node2        online
aggr2         node1        node2        online
aggr3         node1        node2        online
aggr4         node1        node2        online

4 entries were displayed.
....
. 执行以下操作之一：
+
[cols="35,65"]
|===
| 如果命令位于中 <<man_prepare_nodes_step9,第 9 步>>... | 那么 ... 


| 输出为空 | 跳过步骤 11 ，然后转到 <<man_prepare_nodes_step12,第 12 步>>。 


| 具有输出 | 转至 <<man_prepare_nodes_step11,第 11 步>>。 
|===
. [[man_prepare_nodes_step11]] 如果 node1 或 node2 拥有其当前所有者而非主所有者的聚合，请完成以下子步骤：
+
.. 将配对节点当前拥有的聚合返回到主所有者节点：
+
`storage failover giveback -ofnode home_node_name`

.. 验证 node1 和 node2 均不拥有其当前所有者（而不是主所有者）的聚合：
+
`storage aggregate show -nodes <node_name> -is-home false -fields owner-name ， home-name ， state`

+
以下示例显示了当节点同时是聚合的当前所有者和主所有者时命令的输出：

+
....
cluster::> storage aggregate show -nodes node1
          -is-home true -fields owner-name,home-name,state

aggregate     home-name    owner-name   state
------------- ------------ ------------ ------
aggr1         node1        node1        online
aggr2         node1        node1        online
aggr3         node1        node1        online
aggr4         node1        node1        online

4 entries were displayed.
....


. 【 ｛ man_prepare_nodes_step12]] 确认 node1 和 node2 可以访问彼此的存储，并确认没有磁盘缺失：
+
`storage failover show -fields local-missing-disks ， partner-missing-disks`

+
以下示例显示了未缺少磁盘时的输出：

+
....
cluster::> storage failover show -fields local-missing-disks,partner-missing-disks

node     local-missing-disks partner-missing-disks
-------- ------------------- ---------------------
node1    None                None
node2    None                None
....
+
如果缺少任何磁盘，请参见 link:other_references.html["参考资料"] 使用 cli_ 链接到 _Disk 和聚合管理，使用 cli_ 链接到 _Logical storage management 以及 _High Availability management_ ，为 HA 对配置存储。

. 确认 node1 和 node2 运行状况良好且有资格加入集群：
+
`cluster show`

+
以下示例显示了两个节点均符合条件且运行状况良好时的输出：

+
....
cluster::> cluster show

Node                  Health  Eligibility
--------------------- ------- ------------
node1                 true    true
node2                 true    true
....
. 将权限级别设置为高级：
+
`set -privilege advanced`

. 【 ｛ man_prepare_nodes_step15]] 确认 node1 和 node2 运行的是相同的 ONTAP 版本：
+
`ssystem node image show -node <node1 ， node2 > -iscurrent true`

+
以下示例显示了命令的输出：

+
....
cluster::*> system node image show -node node1,node2 -iscurrent true

                 Is      Is                Install
Node     Image   Default Current Version   Date
-------- ------- ------- ------- --------- -------------------
node1
         image1  true    true    9.1         2/7/2017 20:22:06
node2
         image1  true    true    9.1         2/7/2017 20:20:48

2 entries were displayed.
....
. 验证 node1 和 node2 均不拥有属于集群中其他节点的任何数据 LIF ，并检查输出中的 `Current Node` 和 `is Home` 列：
+
`network interface show -role data -is-home false -curr-node node_name`

+
以下示例显示了 node1 中没有归集群中其他节点所有的 LIF 时的输出：

+
....
cluster::> network interface show -role data -is-home false -curr-node node1
 There are no entries matching your query.
....
+
以下示例显示了 node1 拥有另一节点主拥有的数据 LIF 时的输出：

+
....
cluster::> network interface show -role data -is-home false -curr-node node1

            Logical    Status     Network            Current       Current Is
Vserver     Interface  Admin/Oper Address/Mask       Node          Port    Home
----------- ---------- ---------- ------------------ ------------- ------- ----
vs0
            data1      up/up      172.18.103.137/24  node1         e0d     false
            data2      up/up      172.18.103.143/24  node1         e0f     false

2 entries were displayed.
....
. 如果中的输出 <<man_prepare_nodes_step15,第 15 步>> 显示 node1 或 node2 拥有集群中其他节点拥有的任何数据 LIF ，请将这些数据 LIF 从 node1 或 node2 迁移出：
+
`network interface revert -vserver * -lif *`

+
有关 `network interface revert` 命令的详细信息，请参见 link:other_references.html["参考资料"] 链接到 _Microsoft ONTAP 9 命令：手册页参考 _ 。

. 检查 node1 或 node2 是否拥有任何故障磁盘：
+
`storage disk show -nodelist <node1 ， node2 > -broken`

+
如果任何磁盘出现故障，请按照 _Disk 和使用 cli_ 进行聚合管理中的说明将其删除。请参见 link:other_references.html["参考资料"] 使用 cli_ 链接到 _Disk 和聚合管理。）

. 通过完成以下子步骤并记录每个命令的输出，收集有关 node1 和 node2 的信息：

